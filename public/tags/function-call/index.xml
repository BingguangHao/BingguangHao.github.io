<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Function Call on Agent</title>
    <link>http://localhost:1313/tags/function-call/</link>
    <description>Recent content in Function Call on Agent</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Fri, 30 May 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/function-call/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Enhancing Large Language Models&#39; Function Calling via Self-Refinement Multiscale Loss and Automated Data Refinement</title>
      <link>http://localhost:1313/post/chapter-1/</link>
      <pubDate>Fri, 30 May 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/chapter-1/</guid>
      <description>&lt;p&gt;Function call becomes a fundamental concept in Large Language Models, enabling more efficient interaction.&lt;/p&gt;&#xA;&lt;p&gt;We propose FunReason, FunReason enhances LLMs&amp;rsquo; function calling by balancing reasoning and execution accuracy. Using automated data refinement and Self-Refinement Multiscale Loss (SRML), it generates high-quality training data for query parseability, reasoning coherence, and precise function calls. SRML optimizes both aspects during training, matching GPT-4o performance while minimizing forgetting.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Overview of FunReason&amp;rsquo;s data refinement pipeline.&lt;/strong&gt; The pipeline consists of five stages: Function Call Classification, Query and Tool Identification, CoT Identification, Function and Parameter Identification, and Format Identification. Each stage ensures specific aspects of data quality, with failing examples either being discarded or regenerated.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
